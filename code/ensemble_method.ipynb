{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# see https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "%pylab inline\n",
    "\n",
    "# sets backend to render higher res images\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "#######################\n",
    "#       imports       #\n",
    "#######################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from mlxtend.classifier import StackingClassifier # <-- note: this is not from sklearn!\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, \n",
    "                              AdaBoostClassifier, BaggingRegressor)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "\n",
    "# change margin size of jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pickle data\n",
    "\n",
    "with open(\"data/small_images_X_values.pkl\", \"rb\") as pfile:\n",
    "    X_data = pickle.load(pfile)\n",
    "with open(\"data/small_images_y_values.pkl\", \"rb\") as pfile:\n",
    "    y_data = pickle.load(pfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162, 108,  61, ..., 157,  90,  19],\n",
       "       [ 26,  44,  94, ..., 143, 152, 125],\n",
       "       [ 58,  62,  73, ..., 150, 134, 121],\n",
       "       [103, 105, 100, ..., 140,  98,  58],\n",
       "       [ 20,   7,   1, ...,   2,   4,   1]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up models for ensemble. Logistic Regression didn't converge so I used an ada model instead\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "lr_model = LogisticRegression()\n",
    "nb_model = GaussianNB()\n",
    "ada_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=123)\n",
    "X_train, X_cross, y_train, y_cross = train_test_split(X_train, y_train, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), GaussianNB(priors=None, var_smoothing=1e-09), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "\n",
    "model_names = [\"ada_model\", \"nb_model\", \"rf_model\"]\n",
    "model_vars = [eval(n) for n in model_names]\n",
    "print(model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list(zip(model_names, model_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('ada_model', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)), ('nb_model', GaussianNB(priors=None, var_smoothing=1e-09)), ('rf_model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard',\n",
    "                                    n_jobs=-1)\n",
    "voting_classifer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357608695652174"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard classfier wasn't much better than just random forest and took much longer so went back to random forest\n",
    "y_pred = voting_classifer.predict(X_cross)\n",
    "accuracy_score(y_cross, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('ada_model', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)), ('nb_model', GaussianNB(priors=None, var_smoothing=1e-09)), ('rf_model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soft was even worse!\n",
    "\n",
    "voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft',\n",
    "                                    n_jobs=-1)\n",
    "voting_classifer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6023913043478261"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = voting_classifer.predict(X_cross)\n",
    "accuracy_score(y_cross, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
